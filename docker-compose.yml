# version: '3.1'

services:
  mysql:
    image: mysql:8.0
    container_name: mysql
    restart: always
    env_file:
      - .env
    ports:
      - 3306:3306
    volumes:
      - mysql_data:/var/lib/mysql
      - ./dataset:/var/lib/mysql-files
      - ./init_db_scripts:/docker-entrypoint-initdb.d
    command: --local_infile=1
    networks:
      - my-network
  
  zookeeper:
    image: quay.io/debezium/zookeeper:3.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - 2181:2181
      - 2888:2888
      - 3888:3888
    networks:
      - my-network

  kafka:
    image: quay.io/debezium/kafka:3.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    env_file:
      - .env
    networks:
      - my-network

  debezium:
    image: quay.io/debezium/connect:3.0
    container_name: debezium
    depends_on:
      - kafka
      - mysql
    ports:
      - 8083:8083
    env_file:
      - .env
    networks:
      - my-network

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - 9089:8080
    env_file:
      - .env
    networks:
      - my-network

  minio:
    image: quay.io/minio/minio
    hostname: minio
    container_name: minio
    ports:
     - 9000:9000
     - 9001:9001
    env_file:
      - .env
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      - my-network

  spark-master:
    # image: docker.io/bitnami/spark:3.3
    build: 
      context: ./spark
      dockerfile: ./Dockerfile
    container_name: spark-master
    env_file:
      - envs/spark-master.env
    ports:
      - 7077:7077
      - 8080:8080
    volumes:
      - ./spark/stream.py:/app/stream.py
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    depends_on:
      - kafka
      - minio
    networks:
      - my-network

  spark-worker:
    image: docker.io/bitnami/spark:3.5
    container_name: spark-worker
    env_file:
      - envs/spark-worker.env
    volumes:
      # - ./spark/stream.py:/app/stream.py
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    depends_on:
      - spark-master
    # entrypoint: /app/entrypoint.sh
    # command: spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 /app/stream.py
    networks:
      - my-network
  
  # spark-notebook:
  #   build:
  #     context: ./notebook
  #     dockerfile: ./Dockerfile
  #   container_name: spark-notebook
  #   user: root
  #   environment:
  #     - JUPYTER_ENABLE_LAB=yes
  #     - GRANT_SUDO=yes
  #   volumes:
  #     - ./notebook:/home/jovyan/work
  #     - ./spark/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
  #   ports:
  #     - 4040:4040
  #     - 8888:8888
  #   networks:
  #     - my-network

volumes:
  mysql_data:
  minio_data:

networks:
  my-network:
    driver: bridge